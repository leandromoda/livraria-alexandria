n        file = STATE_DIR / f\"{name}_part_{i:03}.json\"\n\n        with open(file, \"w\", encoding=\"utf-8\") as f:\n            f.write(part)\n\n        paths.append(file)\n\n    return paths\n\n\n# =========================\n# TREE\n# =========================\n\ndef build_site_tree():\n\n    lines = []\n\n    for folder in SITE_FOLDERS:\n\n        base = PROJECT_ROOT / folder\n\n        if not base.exists():\n            continue\n\n        for root, dirs, files in os.walk(base):\n\n            dirs[:] = [\n                d for d in dirs\n                if d not in EXCLUDE_DIRS\n            ]\n\n            rel = Path(root).relative_to(PROJECT_ROOT)\n            lines.append(str(rel))\n\n    return \"\\n\".join(lines)\n\n\n# =========================\n# FILE COLLECT\n# =========================\n\ndef collect_files(folders, extensions=None):\n\n    collected = {}\n\n    for folder in folders:\n\n        base = PROJECT_ROOT / folder\n\n        if not base.exists():\n            continue\n\n        for root, dirs, files in os.walk(base):\n\n            dirs[:] = [\n                d for d in dirs\n                if d not in EXCLUDE_DIRS\n            ]\n\n            for file in files:\n\n                if extensions and not any(\n                    file.endswith(ext)\n                    for ext in extensions\n                ):\n                    continue\n\n                path = Path(root) / file\n                rel = str(path.relative_to(PROJECT_ROOT))\n\n                if file.endswith(\".db\"):\n                    collected[rel] = dump_sqlite(path)\n                else:\n                    collected[rel] = read_file(path)\n\n    return collected\n\n\n# =========================\n# FILE READ\n# =========================\n\ndef read_file(path):\n\n    try:\n        return path.read_text(encoding=\"utf-8\")\n    except:\n        return \"[binary or unreadable]\"\n\n\n# =========================\n# SQLITE DUMP\n# =========================\n\ndef dump_sqlite(path):\n\n    if not path.exists():\n        return {\"error\": \"db not found\"}\n\n    try:\n\n        conn = sqlite3.connect(path)\n        cursor = conn.cursor()\n\n        cursor.execute(\n            \"SELECT name FROM sqlite_master WHERE type='table';\"\n        )\n\n        tables = [t[0] for t in cursor.fetchall()]\n\n        dump = {}\n\n        for table in tables:\n\n            cursor.execute(\n                f\"PRAGMA table_info({table});\"\n            )\n\n            cols = cursor.fetchall()\n\n            dump[table] = [\n                {\n                    \"name\": c[1],\n                    \"type\": c[2]\n                }\n                for c in cols\n            ]\n\n        conn.close()\n\n        return dump\n\n    except:\n        return {\"error\": \"failed to read sqlite\"}\n\n\n# =========================\n# ABSTRACT LOADERS\n# =========================\n\ndef load_project_state():\n\n    path = PROJECT_ROOT / \"project_state.json\"\n\n    if path.exists():\n        return path.read_text(encoding=\"utf-8\")\n\n    return \"project_state.json não encontrado.\"\n\n\ndef load_db_schema():\n\n    path = PROJECT_ROOT / \"database_schema.json\"\n\n    if path.exists():\n        return path.read_text(encoding=\"utf-8\")\n\n    return \"database_schema.json não encontrado.\"\n\n\n# =========================\n# MODES\n# =========================\n\ndef export_site():\n\n    name = f\"{now()}_site_bootstrap\"\n\n    data = {\n        \"tree_site\": build_site_tree(),\n        \"project_state\": load_project_state(),\n        \"database_schema_abstract\": load_db_schema(),\n        \"files\": collect_files(\n            SITE_FOLDERS,\n            SITE_EXTENSIONS\n        )\n    }\n\n    return write_parts(name, data)\n\n\ndef export_pipeline():\n\n    name = f\"{now()}_pipeline_full\"\n\n    data = {\n        \"sqlite_dump\": dump_sqlite(SQLITE_DB_PATH),\n        \"files\": collect_files(\n            PIPELINE_FOLDERS,\n            PIPELINE_EXTENSIONS\n        )\n    }\n\n    return write_parts(name, data)\n\n\ndef export_full():\n\n    name = f\"{now()}_full_snapshot\"\n\n    data = {\n        \"tree_site\": build_site_tree(),\n        \"sqlite_dump\": dump_sqlite(SQLITE_DB_PATH),\n        \"files\": collect_files(\n            [\".\"],\n            None\n        )\n    }\n\n    return write_parts(name, data)\n\n\n# =========================\n# ENTRY\n# =========================\n\ndef export_state_transcript(mode=\"site\"):\n\n    if mode == \"site\":\n        paths = export_site()\n\n    elif mode == \"pipeline\":\n        paths = export_pipeline()\n\n    elif mode == \"full\":\n        paths = export_full()\n\n    else:\n        print(\"Modo inválido.\")\n        return\n\n    print(\"\\nTranscript gerado:\\n\")\n\n    for p in paths:\n        print(p)\n\n    print(\"\\nTotal partes:\", len(paths), \"\\n\")\n\n\n# =========================\n\nif __name__ == \"__main__\":\n    export_state_transcript(\"site\")\n",
    "scripts\\steps\\prospect.py": "# ============================================\n# LIVRARIA ALEXANDRIA — PROSPECT\n# Lock Safe + Path Safe + Standalone Safe\n# ============================================\n\nimport os\nimport sys\nimport time\nimport uuid\nimport hashlib\nimport sqlite3\nimport requests\nimport importlib.util\n\nfrom datetime import datetime\n\n\n# ============================================\n# LOAD CLUSTERS (FILE SAFE)\n# ============================================\n\nCURRENT_DIR = os.path.dirname(__file__)\n\nCLUSTERS_PATH = os.path.join(\n    CURRENT_DIR,\n    \"_clusters.py\"\n)\n\nspec = importlib.util.spec_from_file_location(\n    \"clusters_module\",\n    CLUSTERS_PATH\n)\n\nclusters_module = importlib.util.module_from_spec(spec)\nspec.loader.exec_module(clusters_module)\n\nCLUSTERS = clusters_module.CLUSTERS\n\n\n# ============================================\n# DB PATH — CORRIGIDO (scripts/data)\n# ============================================\n\nSCRIPTS_DIR = os.path.abspath(\n    os.path.join(CURRENT_DIR, \"..\")\n)\n\nDATA_DIR = os.path.join(SCRIPTS_DIR, \"data\")\nos.makedirs(DATA_DIR, exist_ok=True)\n\nDB_PATH = os.path.join(\n    DATA_DIR,\n    \"books.db\"\n)\n\n\n# ============================================\n# CONFIG\n# ============================================\n\nOPENLIBRARY_URL = \"https://openlibrary.org/search.json\"\nGOOGLE_BOOKS_URL = \"https://www.googleapis.com/books/v1/volumes\"\n\nHEARTBEAT_INTERVAL = 30\n\nLANG_MAP = {\n    \"pt\": \"por\",\n    \"en\": \"eng\",\n    \"es\": \"spa\",\n    \"it\": \"ita\"\n}\n\n\n# ============================================\n# HEARTBEAT\n# ============================================\n\n_last_event = time.time()\n\n\ndef ts():\n    return datetime.now().strftime(\"%H:%M:%S\")\n\n\ndef beat(msg=\"Script ativo…\"):\n    global _last_event\n\n    now_ts = time.time()\n\n    if now_ts - _last_event >= HEARTBEAT_INTERVAL:\n        print(\n            f\"[{ts()}] {msg} último evento há {int(now_ts - _last_event)}s\"\n        )\n\n    _last_event = now_ts\n\n\n# ============================================\n# DB SAFE\n# ============================================\n\ndef get_conn():\n\n    conn = sqlite3.connect(\n        DB_PATH,\n        timeout=60,\n        isolation_level=None\n    )\n\n    conn.execute(\"PRAGMA journal_mode=WAL;\")\n    conn.execute(\"PRAGMA synchronous=NORMAL;\")\n\n    return conn\n\n\ndef ensure_schema():\n\n    conn = get_conn()\n    cur = conn.cursor()\n\n    cur.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS livros (\n        id TEXT PRIMARY KEY,\n        titulo TEXT NOT NULL,\n        slug TEXT UNIQUE,\n        autor TEXT,\n        descricao TEXT,\n        isbn TEXT,\n        ano_publicacao INTEGER,\n        imagem_url TEXT,\n        idioma TEXT,\n        cluster TEXT,\n        fonte TEXT,\n        status_slug INTEGER DEFAULT 0,\n        status_dedup INTEGER DEFAULT 0,\n        status_synopsis INTEGER DEFAULT 0,\n        status_review INTEGER DEFAULT 0,\n        status_cover INTEGER DEFAULT 0,\n        status_publish INTEGER DEFAULT 0,\n        created_at DATETIME,\n        updated_at DATETIME\n    )\n    \"\"\")\n\n    conn.commit()\n    conn.close()\n\n\n# ============================================\n# ID STRATEGY\n# ============================================\n\ndef generate_id(titulo, isbn):\n\n    base = isbn if isbn else titulo\n\n    hash_id = hashlib.sha1(\n        base.encode(\"utf-8\")\n    ).hexdigest()\n\n    return str(uuid.uuid4())[:8] + hash_id[:16]\n\n\n# ============================================\n# EXISTS\n# ============================================\n\ndef exists(titulo):\n\n    conn = get_conn()\n    cur = conn.cursor()\n\n    cur.execute(\n        \"SELECT 1 FROM livros WHERE titulo = ? LIMIT 1\",\n        (titulo,)\n    )\n\n    res = cur.fetchone()\n    conn.close()\n\n    return res is not None\n\n\n# ============================================\n# INSERT\n# ============================================\n\ndef insert_book(data, cluster):\n\n    if exists(data[\"titulo\"]):\n        print(f\"[{ts()}] SKIP duplicado → {data['titulo']}\")\n        return False\n\n    livro_id = generate_id(\n        data[\"titulo\"],\n        data[\"isbn\"]\n    )\n\n    now = datetime.utcnow()\n\n    conn = get_conn()\n    cur = conn.cursor()\n\n    for attempt in range(5):\n\n        try:\n\n            cur.execute(\"\"\"\n                INSERT INTO livros (\n                    id,\n                    titulo,\n                    autor,\n                    isbn,\n                    ano_publicacao,\n                    idioma,\n                    cluster,\n                    fonte,\n                    created_at,\n                    updated_at\n                )\n                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n            \"\"\", (\n                livro_id,\n                data[\"titulo\"],\n                data[\"autor\"],\n                data[\"isbn\"],\n                data[\"ano\"],\n                data[\"idioma\"],\n                cluster,\n                data[\"fonte\"],\n                now,\n                now\n            ))\n\n            conn.commit()\n            conn.close()\n            return True\n\n        except sqlite3.OperationalError as e:\n\n            if \"locked\" in str(e):\n                time.sleep(1)\n                continue\n            else:\n                conn.close()\n                raise\n\n    conn.close()\n    return False\n\n\n# ============================================\n# FETCHERS\n# ============================================\n\ndef fetch_openlibrary(query, idioma, limit=20):\n\n    beat()\n\n    lang_code = LANG_MAP.get(idioma, \"por\")\n\n    try:\n        res = requests.get(\n            OPENLIBRARY_URL,\n            params={\n                \"q\": query,\n                \"language\": lang_code,\n                \"limit\": limit\n            },\n            timeout=20\n        )\n\n        docs = res.json().get(\"docs\", [])\n        books = []\n\n        for d in docs:\n\n            langs = d.get(\"language\", [])\n            if lang_code not in langs:\n                continue\n\n            titulo = d.get(\"title\")\n            autores = \", \".join(d.get(\"author_name\", []))\n\n            isbn_list = d.get(\"isbn\", [])\n            isbn = isbn_list[0] if isbn_list else None\n\n            ano = d.get(\"first_publish_year\")\n\n            if not titulo:\n                continue\n\n            books.append({\n                \"titulo\": titulo,\n                \"autor\": autores,\n                \"isbn\": isbn,\n                \"ano\": ano,\n                \"idioma\": idioma,\n                \"fonte\": \"openlibrary\"\n            })\n\n        return books\n\n    except Exception as e:\n        print(f\"[{ts()}] ERRO OL → {e}\")\n        return []\n\n\ndef fetch_google(query, idioma, limit=20):\n\n    beat()\n\n    try:\n        res = requests.get(\n            GOOGLE_BOOKS_URL,\n            params={\n                \"q\": query,\n                \"maxResults\": limit,\n                \"langRestrict\": idioma,\n                \"printType\": \"books\"\n            },\n            timeout=20\n        )\n\n        items = res.json().get(\"items\", [])\n        books = []\n\n        for item in items:\n\n            info = item.get(\"volumeInfo\", {})\n\n            if info.get(\"language\") != idioma:\n                continue\n\n            titulo = info.get(\"title\")\n            autores = \", \".join(info.get(\"authors\", []))\n\n            industry = info.get(\"industryIdentifiers\", [])\n\n            isbn = None\n            for i in industry:\n                if \"ISBN\" in i[\"type\"]:\n                    isbn = i[\"identifier\"]\n                    break\n\n            ano = info.get(\"publishedDate\", \"\")[:4]\n\n            if not titulo:\n                continue\n\n            books.append({\n                \"titulo\": titulo,\n                \"autor\": autores,\n                \"isbn\": isbn,\n                \"ano\": ano,\n                \"idioma\": idioma,\n                \"fonte\": \"google\"\n            })\n\n        return books\n\n    except Exception as e:\n        print(f\"[{ts()}] ERRO GOOGLE → {e}\")\n        return []\n\n\n# ============================================\n# RUN\n# ============================================\n\ndef run(idioma, pacote):\n\n    ensure_schema()\n\n    inseridos = 0\n\n    for cluster, queries in CLUSTERS.items():\n\n        print(f\"[{ts()}] CLUSTER → {cluster}\")\n\n        for query in queries:\n\n            if inseridos >= pacote:\n                print(f\"[{ts()}] Pacote atingido — STOP.\")\n                return\n\n            print(f\"[{ts()}] QUERY → {query}\")\n\n            ol_books = fetch_openlibrary(query, idioma)\n            g_books = fetch_google(query, idioma)\n\n            for book in ol_books + g_books:\n\n                if inseridos >= pacote:\n                    print(f\"[{ts()}] Pacote atingido — STOP.\")\n                    return\n\n                if insert_book(book, cluster):\n                    inseridos += 1\n                    print(\n                        f\"[{ts()}] INSERT {inseridos}/{pacote} → {book['titulo']}\"\n                    )\n\n    print(f\"[{ts()}] Fim da prospecção.\")\n\n\n# ============================================\n# CLI\n# ============================================\n\nif __name__ == \"__main__\":\n\n    if len(sys.argv) < 3:\n        print(\"Uso: prospect.py <idioma> <pacote>\")\n        sys.exit(1)\n\n    idioma = sys.argv[1]\n    pacote = int(sys.argv[2])\n\n    run(idioma, pacote)\n",
    "scripts\\steps\\publish.py": "# ============================================\n# LIVRARIA ALEXANDRIA — PUBLISH\n# Path Safe + Retry Safe + Roundtrip Safe\n# ============================================\n\nimport requests\nimport uuid\nimport time\n\nfrom datetime import datetime\n\nfrom core.db import get_conn\nfrom core.logger import log\n\n\n# =========================\n# CONFIG\n# =========================\n\nSUPABASE_URL = \"https://ncnexkuiiuzwujqurtsa.supabase.co\"\nSUPABASE_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im5jbmV4a3VpaXV6d3VqcXVydHNhIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc2OTU0MTY2MCwiZXhwIjoyMDg1MTE3NjYwfQ.CacLDlVd0noDzcuVJnxjx3eMr7SjI_19rAsDZeQh6S8\"\n\nTABLE_URL = f\"{SUPABASE_URL}/rest/v1/livros\"\n\nHEADERS = {\n    \"apikey\": SUPABASE_KEY,\n    \"Authorization\": f\"Bearer {SUPABASE_KEY}\",\n    \"Content-Type\": \"application/json\",\n    \"Prefer\": \"return=representation,resolution=merge-duplicates\"\n}\n\nTIMEOUT = 60\nMAX_RETRIES = 3\n\n\n# =========================\n# FETCH\n# =========================\n\ndef fetch_pending(idioma, limit):\n\n    conn = get_conn()\n    cur = conn.cursor()\n\n    cur.execute(\"\"\"\n        SELECT\n            id,\n            titulo,\n            slug,\n            autor,\n            descricao,\n            isbn,\n            ano_publicacao,\n            imagem_url\n        FROM livros\n        WHERE status_publish = 0\n        AND status_review = 1\n        AND is_publishable = 1\n        AND idioma = ?\n        LIMIT ?\n    \"\"\", (idioma, limit))\n\n    rows = cur.fetchall()\n    conn.close()\n\n    return rows\n\n\n# =========================\n# PAYLOAD\n# =========================\n\ndef build_payload(row):\n\n    now = datetime.utcnow().isoformat()\n\n    supabase_uuid = str(uuid.uuid4())\n\n    return {\n        \"id\": supabase_uuid,\n        \"titulo\": row[1],\n        \"slug\": row[2],\n        \"autor\": row[3],\n        \"descricao\": row[4],\n        \"isbn\": row[5],\n        \"ano_publicacao\": row[6],\n        \"imagem_url\": row[7],\n        \"created_at\": now,\n        \"updated_at\": now,\n    }\n\n\n# =========================\n# UPSERT\n# =========================\n\ndef upsert_book(payload):\n\n    for attempt in range(MAX_RETRIES):\n\n        try:\n\n            res = requests.post(\n                TABLE_URL,\n                headers=HEADERS,\n                json=payload,\n                timeout=TIMEOUT\n            )\n\n            if res.status_code not in [200, 201]:\n\n                log(\n                    f\"SUPABASE ERRO {res.status_code} → \"\n                    f\"{res.text[:200]}\"\n                )\n\n                time.sleep(2)\n                continue\n\n            data = res.json()\n\n            if isinstance(data, list) and data:\n                return data[0][\"id\"]\n\n            return payload[\"id\"]\n\n        except Exception as e:\n\n            log(f\"RETRY SUPABASE → {e}\")\n            time.sleep(2)\n\n    return None\n\n\n# =========================\n# FLAG LOCAL\n# =========================\n\ndef mark_published(local_id, supabase_id):\n\n    conn = get_conn()\n    cur = conn.cursor()\n\n    cur.execute(\"\"\"\n        UPDATE livros\n        SET\n            status_publish = 1,\n            supabase_id = ?,\n            updated_at = CURRENT_TIMESTAMP\n        WHERE id = ?\n    \"\"\", (supabase_id, local_id))\n\n    conn.commit()\n    conn.close()\n\n\n# =========================\n# RUN\n# =========================\n\ndef run(idioma, pacote=10):\n\n    rows = fetch_pending(idioma, pacote)\n\n    if not rows:\n        log(\n            f\"Nada pendente para publicação \"\n            f\"no idioma [{idioma}].\"\n        )\n        return\n\n    inserted = 0\n    failed = 0\n\n    for row in rows:\n\n        payload = build_payload(row)\n\n        supabase_id = upsert_book(payload)\n\n        if not supabase_id:\n            failed += 1\n            log(f\"FALHA → {row[1]}\")\n            continue\n\n        mark_published(row[0], supabase_id)\n\n        inserted += 1\n        log(f\"PUBLICADO → {row[1]}\")\n\n    log(\n        f\"PUBLICAÇÃO CONCLUÍDA [{idioma}] → \"\n        f\"{inserted} | falhas {failed}\"\n    )\n",
    "scripts\\steps\\quality_gate.py": "# ============================================\n# LIVRARIA ALEXANDRIA — QUALITY GATE\n# Path Safe + Migration Safe\n# ============================================\n\nimport sqlite3\n\nfrom datetime import datetime\n\nfrom core.db import get_conn\nfrom core.logger import log\n\n\n# =========================\n# SCHEMA MIGRATION\n# =========================\n\nREQUIRED_COLUMNS = {\n    \"is_publishable\": \"INTEGER DEFAULT 0\",\n    \"publish_blockers\": \"TEXT\",\n    \"quality_score\": \"INTEGER DEFAULT 0\",\n    \"last_quality_check\": \"DATETIME\",\n    \"supabase_id\": \"TEXT\"\n}\n\n\ndef ensure_schema():\n\n    conn = get_conn()\n    cur = conn.cursor()\n\n    cur.execute(\"PRAGMA table_info(livros)\")\n    existing = [row[1] for row in cur.fetchall()]\n\n    for col, ddl in REQUIRED_COLUMNS.items():\n\n        if col in existing:\n            continue\n\n        log(f\"[QUALITY GATE] Criando coluna: {col}\")\n\n        cur.execute(\n            f\"ALTER TABLE livros ADD COLUMN {col} {ddl}\"\n        )\n\n    conn.commit()\n    conn.close()\n\n\n# =========================\n# QUALITY RULES\n# =========================\n\ndef evaluate_row(row):\n\n    blockers = []\n    score = 0\n\n    # SLUG\n    if row[\"slug\"]:\n        score += 1\n    else:\n        blockers.append(\"missing_slug\")\n\n    # SINOPSE\n    if row[\"descricao\"] and len(row[\"descricao\"]) >= 120:\n        score += 1\n    else:\n        blockers.append(\"weak_synopsis\")\n\n    # CAPA\n    if row[\"imagem_url\"]:\n        score += 1\n    else:\n        blockers.append(\"missing_cover\")\n\n    # REVIEW\n    if row[\"status_review\"] == 1:\n        score += 1\n    else:\n        blockers.append(\"not_reviewed\")\n\n    publishable = 1 if score >= 3 else 0\n\n    return publishable, score, blockers\n\n\n# =========================\n# MAIN EVALUATION\n# =========================\n\ndef evaluate_quality(idioma, limit=None):\n\n    ensure_schema()\n\n    conn = get_conn()\n    conn.row_factory = sqlite3.Row\n    cur = conn.cursor()\n\n    query = \"\"\"\n        SELECT *\n        FROM livros\n        WHERE status_publish = 0\n        AND idioma = ?\n    \"\"\"\n\n    params = [idioma]\n\n    if limit:\n        query += \" LIMIT ?\"\n        params.append(limit)\n\n    cur.execute(query, params)\n\n    rows = cur.fetchall()\n\n    evaluated = 0\n    publishable_count = 0\n    blocked = 0\n\n    for row in rows:\n\n        publishable, score, blockers = evaluate_row(row)\n\n        cur.execute(\"\"\"\n            UPDATE livros\n            SET\n                is_publishable = ?,\n                quality_score = ?,\n                publish_blockers = ?,\n                last_quality_check = ?,\n                updated_at = ?\n            WHERE id = ?\n        \"\"\", (\n            publishable,\n            score,\n            \",\".join(blockers) if blockers else None,\n            datetime.utcnow().isoformat(),\n            datetime.utcnow().isoformat(),\n            row[\"id\"]\n        ))\n\n        evaluated += 1\n\n        if publishable:\n            publishable_count += 1\n        else:\n            blocked += 1\n\n    conn.commit()\n    conn.close()\n\n    log(\n        f\"[QUALITY GATE][{idioma}] \"\n        f\"Avaliados: {evaluated} | \"\n        f\"Publishable: {publishable_count} | \"\n        f\"Bloqueados: {blocked}\"\n    )\n",
    "scripts\\steps\\review.py": "# ============================================\n# LIVRARIA ALEXANDRIA — REVIEW\n# Synopsis Review + Slug Rebuild\n# ============================================\n\nimport requests\nimport re\nimport unicodedata\nimport time\n\nfrom core.db import get_conn\nfrom core.logger import log\n\n\n# =========================\n# CONFIG\n# =========================\n\nOLLAMA_URL = \"http://localhost:11434/api/generate\"\nMODEL = \"phi3:mini\"\n\nTIMEOUT = 300\nMAX_RETRIES = 3\n\n\n# =========================\n# PROMPT\n# =========================\n\ndef build_prompt(texto):\n\n    return f\"\"\"\nRevise a sinopse abaixo.\n\nObjetivos:\n\n- Corrigir gramática\n- Corrigir concordância\n- Melhorar fluidez\n- Remover repetições\n- Máx 80 palavras\n- Não adicionar conteúdo novo\n\nSinopse:\n\n{texto}\n\"\"\"\n\n\n# =========================\n# LLM CALL\n# =========================\n\ndef review_text(texto):\n\n    for attempt in range(MAX_RETRIES):\n\n        try:\n\n            res = requests.post(\n                OLLAMA_URL,\n                json={\n                    \"model\": MODEL,\n                    \"prompt\": build_prompt(texto),\n                    \"stream\": False,\n                    \"options\": {\n                        \"temperature\": 0.2,\n                        \"num_predict\": 180\n                    }\n                },\n                timeout=TIMEOUT\n            )\n\n            text = res.json()[\"response\"].strip()\n\n            if len(text) > 30:\n                return text\n\n        except Exception:\n            log(f\"Retry Review ({attempt+1})\")\n            time.sleep(2)\n\n    return None\n\n\n# =========================\n# SLUG\n# =========================\n\ndef base_slug(text):\n\n    text = unicodedata.normalize(\"NFKD\", text)\n    text = text.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n    text = text.lower()\n\n    text = re.sub(r\"[^a-z0-9\\s-]\", \"\", text)\n    text = re.sub(r\"\\s+\", \"-\", text)\n\n    return text.strip(\"-\")\n\n\ndef slug_exists(slug, book_id):\n\n    conn = get_conn()\n    cur = conn.cursor()\n\n    cur.execute(\"\"\"\n        SELECT 1\n        FROM livros\n        WHERE slug = ?\n        AND id != ?\n        LIMIT 1\n    \"\"\", (slug, book_id))\n\n    exists = cur.fetchone() is not None\n    conn.close()\n\n    return exists\n\n\ndef revise_slug(titulo, book_id):\n\n    base = base_slug(titulo)\n    slug = base\n    counter = 2\n\n    while slug_exists(slug, book_id):\n        slug = f\"{base}-{counter}\"\n        counter += 1\n\n    return slug\n\n\n# ====